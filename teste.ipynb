{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import seaborn as sns\n",
    "import feature_selection as fs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import prep_utils as pu\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import pointbiserialr\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "PAST_YEARS = 1\n",
    "TEST_YEAR = 10\n",
    "KAGGLE_TEST_YEAR = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect(\"db/ac2.db\")\n",
    "db_cur = db.cursor()\n",
    "\n",
    "[df_awards, df_coaches, df_players_teams, df_players, df_series_post, df_teams_post, df_teams] = pu.db_to_pandas(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping divID in \u001b[1mTeams\u001b[0m...\n"
     ]
    }
   ],
   "source": [
    "# Transform all possible attributes into percentages. (Made / Attempted) & (Offensive & Defensive Rebound %)\n",
    "df_new_teams = pu.prepare_teams(df_teams,df_teams_post,PAST_YEARS)\n",
    "\n",
    "df_new_teams = fs.fs_teams(df_new_teams)\n",
    "\n",
    "df_new_teams = pu.playoff_rank(df_new_teams,df_teams,PAST_YEARS)\n",
    "df_team_results = df_new_teams[[\"year\",\"tmID\",\"confID\",\"playoff\",\"rank\",\"team_playoffs_count\",\"playoff_rank\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping Attribute lgID in \u001b[1mCoaches\u001b[0m...\n",
      "Creating attribute coach previous regular season win ratio...\n",
      "Creating attribute coach playoffs win ratio...\n",
      "Creating attribute coach playoffs count...\n",
      "Creating attribute coach awards count...\n",
      "Dropping attribute post_wins..\n",
      "Dropping attribute post_losses..\n",
      "Dropping attribute won..\n",
      "Dropping attribute lost..\n",
      "\n",
      "\u001b[1mCoaches Null Verification:\u001b[0m\n",
      "year                    0\n",
      "tmID                    0\n",
      "coachID                 0\n",
      "coach_reg_wr            0\n",
      "coach_po_wr             0\n",
      "coach_playoffs_count    0\n",
      "coach_awards            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_new_coaches = pu.prepare_coaches(df_coaches, df_awards,PAST_YEARS)\n",
    "df_new_coaches = pu.group_coaches(df_new_coaches)\n",
    "\n",
    "df_new_coaches.drop(\"coachID\", axis = 1, inplace = True)\n",
    "\n",
    "df_final_coaches = df_new_coaches.copy()\n",
    "df_final_coaches.columns = df_final_coaches.columns.str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping Attribute lgID in \u001b[1mPlayers_Teams\u001b[0m...\n",
      "     year tmid  team_rating\n",
      "0       1  LAS     0.000000\n",
      "1       1  NYL     0.000000\n",
      "2       1  HOU     0.000000\n",
      "3       1  SAC     0.000000\n",
      "4       1  ORL     0.000000\n",
      "5       1  WAS     0.000000\n",
      "6       1  CLE     0.000000\n",
      "7       1  PHO     0.000000\n",
      "8       1  UTA     0.000000\n",
      "9       1  IND     0.000000\n",
      "10      1  CHA     0.000000\n",
      "11      1  DET     0.000000\n",
      "12      1  MIN     0.000000\n",
      "13      1  POR     0.000000\n",
      "14      1  MIA     0.000000\n",
      "15      1  SEA     0.000000\n",
      "16      2  LAS     0.912333\n",
      "17      2  NYL     0.911415\n",
      "18      2  SAC     0.877208\n",
      "19      2  UTA     0.771151\n",
      "20      2  CHA     0.724720\n",
      "21      2  HOU     0.899098\n",
      "22      2  MIA     0.648088\n",
      "23      2  CLE     0.817667\n",
      "24      2  ORL     0.846131\n",
      "25      2  WAS     0.838273\n",
      "26      2  IND     0.743560\n",
      "27      2  POR     0.706193\n",
      "28      2  DET     0.716276\n",
      "29      2  PHO     0.815925\n",
      "30      2  SEA     0.617374\n",
      "31      2  MIN     0.716012\n",
      "32      3  LAS     0.954726\n",
      "33      3  UTA     0.859805\n",
      "34      3  NYL     0.875441\n",
      "35      3  WAS     0.716412\n",
      "36      3  CHA     0.858300\n",
      "37      3  IND     0.704688\n",
      "38      3  HOU     0.792457\n",
      "39      3  SEA     0.674616\n",
      "40      3  CLE     0.779217\n",
      "41      3  SAC     0.874868\n",
      "42      3  POR     0.704449\n",
      "43      3  PHO     0.680037\n",
      "44      3  ORL     0.760030\n",
      "45      3  MIA     0.791992\n",
      "46      3  DET     0.692518\n",
      "47      3  MIN     0.603371\n",
      "48      4  LAS     0.961362\n",
      "49      4  DET     0.643652\n",
      "50      4  CON     0.000000\n",
      "51      4  SAC     0.713122\n",
      "52      4  HOU     0.774453\n",
      "53      4  CHA     0.780772\n",
      "54      4  CLE     0.717335\n",
      "55      4  SEA     0.758935\n",
      "56      4  IND     0.778385\n",
      "57      4  NYL     0.867429\n",
      "58      4  WAS     0.838728\n",
      "59      4  SAS     0.000000\n",
      "60      4  MIN     0.539985\n",
      "61      4  PHO     0.700615\n",
      "62      5  CON     0.856643\n",
      "63      5  SEA     0.778708\n",
      "64      5  LAS     0.949490\n",
      "65      5  DET     0.914296\n",
      "66      5  NYL     0.757567\n",
      "67      5  SAC     0.850964\n",
      "68      5  WAS     0.737162\n",
      "69      5  IND     0.770868\n",
      "70      5  PHO     0.676073\n",
      "71      5  CHA     0.806379\n",
      "72      5  HOU     0.829395\n",
      "73      5  SAS     0.734199\n",
      "74      5  MIN     0.686523\n",
      "75      6  CON     0.931192\n",
      "76      6  SEA     0.928234\n",
      "77      6  NYL     0.840348\n",
      "78      6  IND     0.766072\n",
      "79      6  LAS     0.865967\n",
      "80      6  SAC     0.835865\n",
      "81      6  WAS     0.804248\n",
      "82      6  HOU     0.706399\n",
      "83      6  DET     0.843474\n",
      "84      6  PHO     0.714187\n",
      "85      6  SAS     0.685736\n",
      "86      6  CHA     0.711238\n",
      "87      6  MIN     0.637691\n",
      "88      7  DET     0.696844\n",
      "89      7  CON     0.930767\n",
      "90      7  LAS     0.824120\n",
      "91      7  IND     0.840694\n",
      "92      7  WAS     0.751628\n",
      "93      7  SEA     0.871588\n",
      "94      7  PHO     0.687066\n",
      "95      7  HOU     0.737546\n",
      "96      7  CHA     0.606457\n",
      "97      7  NYL     0.841345\n",
      "98      7  SAC     0.813304\n",
      "99      7  MIN     0.548481\n",
      "100     7  CHI     0.000000\n",
      "101     7  SAS     0.622350\n",
      "102     8  PHO     0.773233\n",
      "103     8  DET     0.936491\n",
      "104     8  CON     0.902848\n",
      "105     8  IND     0.850908\n",
      "106     8  SEA     0.831861\n",
      "107     8  NYL     0.712008\n",
      "108     8  SAC     0.703437\n",
      "109     8  WAS     0.849784\n",
      "110     8  HOU     0.762779\n",
      "111     8  SAS     0.624798\n",
      "112     8  CHI     0.652075\n",
      "113     8  LAS     0.853866\n",
      "114     8  MIN     0.661392\n",
      "115     9  LAS     0.722202\n",
      "116     9  IND     0.861372\n",
      "117     9  DET     0.888784\n",
      "118     9  NYL     0.833995\n",
      "119     9  SEA     0.850751\n",
      "120     9  SAS     0.746074\n",
      "121     9  CON     0.877561\n",
      "122     9  PHO     1.000000\n",
      "123     9  SAC     0.791061\n",
      "124     9  MIN     0.703300\n",
      "125     9  CHI     0.727112\n",
      "126     9  HOU     0.748719\n",
      "127     9  WAS     0.776127\n",
      "128     9  ATL     0.000000\n",
      "129    10  PHO     0.774778\n",
      "130    10  IND     0.844948\n",
      "131    10  LAS     0.914711\n",
      "132    10  SEA     0.800583\n",
      "133    10  DET     0.844141\n",
      "134    10  WAS     0.599861\n",
      "135    10  ATL     0.581072\n",
      "136    10  SAS     0.800304\n",
      "137    10  MIN     0.743947\n",
      "138    10  NYL     0.828984\n",
      "139    10  CON     0.783522\n",
      "140    10  CHI     0.734207\n",
      "141    10  SAC     0.754228\n",
      "142    11  ATL     0.816488\n",
      "143    11  CHI     0.717937\n",
      "144    11  CON     0.734972\n",
      "145    11  IND     0.951452\n",
      "146    11  LAS     0.896314\n",
      "147    11  MIN     0.754071\n",
      "148    11  NYL     0.751490\n",
      "149    11  PHO     0.978688\n",
      "150    11  SAS     0.755962\n",
      "151    11  SEA     0.869611\n",
      "152    11  TUL     0.000000\n",
      "153    11  WAS     0.853112\n"
     ]
    }
   ],
   "source": [
    "df_new_players_teams = pu.prepare_player_teams(df_players_teams,df_awards,PAST_YEARS)\n",
    "# How the team performed in the previous year\n",
    "\n",
    "\n",
    "previous_team_ratings = pu.final_team_ratings(df_players_teams,df_awards, df_players, df_teams, PAST_YEARS)\n",
    "\n",
    "\n",
    "# How the players performed in the previous year\n",
    "#previous_team_player_ratings = pu.final_player_team_ratings(df_teams, df_players_teams, df_awards, df_players, PAST_YEARS)\n",
    "\n",
    "print(previous_team_ratings.to_string())\n",
    "\n",
    "\n",
    "\n",
    "df_players = df_new_players_teams.copy()\n",
    "df_players = fs.fs_players(df_players,0.2)\n",
    "df_players = df_players[df_players['year'] != 1]\n",
    "\n",
    "\n",
    "df_team_results.columns = df_team_results.columns.str.lower()\n",
    "merged_data = pd.merge(df_players, df_team_results, on=['tmid', 'year'], how='left')\n",
    "merged_data = pd.merge(merged_data, df_final_coaches, on=['tmid', 'year'], how='left')\n",
    "merged_data = pd.merge(merged_data, previous_team_ratings, on=['tmid', 'year'], how='left')\n",
    "#merged_data = pd.merge(merged_data, previous_team_player_ratings, on=['tmid', 'year'], how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Point Bisserial Correlation \n",
    "We will use this to check correlation between continuous attributes & target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_assists: 36.39% correlation\n",
      "playoff_rank: 33.90% correlation\n",
      "total_gs: 32.71% correlation\n",
      "total_points: 31.77% correlation\n",
      "coach_po_wr: 31.26% correlation\n",
      "total_minutes: 31.16% correlation\n",
      "coach_reg_wr: 30.47% correlation\n",
      "total_turnovers: 28.44% correlation\n",
      "player_awards: 27.79% correlation\n",
      "total_blocks: 26.30% correlation\n",
      "team_rating: 25.50% correlation\n",
      "total_steals: 24.90% correlation\n",
      "coach_playoffs_count: 24.50% correlation\n",
      "total_pf: 23.19% correlation\n",
      "team_playoffs_count: 19.10% correlation\n",
      "rank: 18.01% correlation\n",
      "total_drebounds_pct: 12.93% correlation\n",
      "total_orebounds_pct: 12.93% correlation\n",
      "coach_awards: 12.93% correlation\n",
      "total_dq: 12.35% correlation\n",
      "total_fg_pct: 10.58% correlation\n",
      "total_gp: 10.20% correlation\n",
      "total_ft_pct: 4.27% correlation\n",
      "total_three_pct: 3.71% correlation\n"
     ]
    }
   ],
   "source": [
    "data1_10 = merged_data[merged_data['year'] != 11]\n",
    "fs.bisserial_corr(data1_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing the dataset in both train & test\n",
    "We will be using year 10 and test and the remaining ones to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "merged_data['tmid'] = label_encoder.fit_transform(merged_data['tmid'])\n",
    "merged_data['confid'] = label_encoder.fit_transform(merged_data['confid'])\n",
    "\n",
    "x = merged_data.drop('playoff', axis=1)\n",
    "y = merged_data['playoff']\n",
    "\n",
    "x_train = merged_data[merged_data['year'].between(0, TEST_YEAR - 1)].drop('playoff', axis=1)\n",
    "y_train = merged_data[merged_data['year'].between(0, TEST_YEAR - 1)]['playoff']\n",
    "\n",
    "x_test = merged_data[merged_data['year'] == TEST_YEAR].drop('playoff', axis=1)\n",
    "y_test = merged_data[merged_data['year'] == TEST_YEAR]['playoff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE\n",
    "We will running RFE on the different models to find out which features produce the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['year', 'tmid', 'player_awards', 'total_minutes', 'total_points',\n",
      "       'total_assists', 'total_steals', 'total_blocks', 'total_turnovers',\n",
      "       'total_pf', 'total_dq', 'total_gs', 'total_gp', 'total_fg_pct',\n",
      "       'total_ft_pct', 'total_three_pct', 'total_orebounds_pct',\n",
      "       'total_drebounds_pct', 'confid', 'playoff', 'rank',\n",
      "       'team_playoffs_count', 'playoff_rank', 'coach_reg_wr', 'coach_po_wr',\n",
      "       'coach_playoffs_count', 'coach_awards', 'team_rating'],\n",
      "      dtype='object')\n",
      "     year  tmid  player_awards  total_minutes  total_points  total_assists  total_steals  total_blocks  total_turnovers  total_pf  total_dq  total_gs  total_gp  total_fg_pct  total_ft_pct  total_three_pct  total_orebounds_pct  total_drebounds_pct  confid  playoff  rank  team_playoffs_count  playoff_rank  coach_reg_wr  coach_po_wr  coach_playoffs_count  coach_awards  team_rating\n",
      "0       2     1              0         3866.6        1302.6          411.2         149.4          46.0            289.2     410.8       3.2      72.4     184.4      0.418740      0.766262         0.319176             0.318664             0.681336       0      1.0   8.0                    0           9.0      0.281250     0.000000                     0             0     0.724720\n",
      "1       2     3              0         5236.4        1731.0          387.2         218.2          76.8            403.4     546.8       5.6     108.8     269.0      0.442889      0.744296         0.329167             0.354633             0.645367       0      1.0   2.0                    1           4.0      0.531250     0.500000                     1             0     0.817667\n",
      "2       2     5              0         3856.0        1428.8          300.8         145.6          45.6            308.0     378.4       1.6     120.0     160.0      0.441215      0.744059         0.262195             0.356275             0.643725       0      0.0   5.0                    0           9.0      0.000000     0.000000                     0             0     0.716276\n",
      "3       2     6              1         2993.2         946.8          133.0         111.8          46.4            175.0     287.4       1.6      78.8     150.2      0.468657      0.808933         0.342792             0.320840             0.679160       1      1.0   2.0                    1           1.0      0.843750     1.000000                     1             0     0.899098\n",
      "4       2     7              0         4513.6        1528.0          336.8         208.0          67.2            339.2     463.2       7.2     104.0     209.6      0.414259      0.759674         0.368421             0.316564             0.683436       0      0.0   7.0                    0           9.0      0.000000     0.000000                     0             0     0.743560\n",
      "5       2     8              0         5489.6        2122.0          502.8         233.0         139.8            394.8     618.0      13.0     155.2     222.6      0.452921      0.784388         0.355597             0.282005             0.717995       1      1.0   1.0                    1           4.0      0.875000     0.500000                     1             1     0.912333\n",
      "6       2     9              0         4468.8        1302.4          290.4         184.0          48.0            308.8     435.2       2.4     131.2     193.6      0.389875      0.680702         0.260870             0.377088             0.622912       0      1.0   6.0                    0           9.0      0.406250     0.000000                     0             0     0.648088\n",
      "7       2    10              1         3055.2        1274.4          226.4         117.6          38.4            245.6     344.8       4.8      72.0     162.4      0.419306      0.774752         0.373333             0.315464             0.684536       1      0.0   6.0                    0           9.0      0.468750     0.000000                     0             0     0.716012\n",
      "8       2    11              1         6099.8        1930.0          527.6         229.4          89.8            444.0     549.8       6.0     149.4     225.8      0.436653      0.753072         0.341201             0.307982             0.692018       0      1.0   1.0                    1           2.0      0.625000     0.571429                     1             0     0.911415\n",
      "9       2    12              0         4224.4        1404.6          328.8         177.6         104.0            320.4     410.0       3.2     105.6     188.2      0.436309      0.719439         0.342351             0.342874             0.657126       0      0.0   3.0                    1           8.0      0.500000     0.333333                     1             0     0.846131\n",
      "10      2    13              0         4558.8        1607.4          331.2         206.6          69.6            311.0     428.8       4.0     110.4     212.4      0.435107      0.781993         0.310147             0.299511             0.700489       1      0.0   4.0                    1           8.0      0.000000     0.000000                     0             0     0.815925\n",
      "11      2    14              0         4984.0        1658.4          360.0         195.2          75.2            392.0     533.6       7.2     142.4     207.2      0.423210      0.728228         0.321053             0.320815             0.679185       1      0.0   7.0                    0           9.0      0.312500     0.000000                     0             0     0.706193\n",
      "12      2    15              0         5673.8        2175.4          494.8         265.2         161.2            417.4     494.6       5.0     166.8     245.8      0.444214      0.711198         0.304135             0.358711             0.641289       1      1.0   3.0                    1           8.0      0.656250     0.000000                     1             0     0.877208\n",
      "13      2    17              0         4302.0        1195.2          295.4         175.2          68.0            358.8     463.2       4.0      84.8     226.8      0.387326      0.634096         0.305598             0.295721             0.704279       1      0.0   8.0                    0           9.0      0.187500     0.000000                     0             0     0.617374\n",
      "14      2    19              0         4897.6        1828.0          392.0         170.4         120.0            406.4     541.6       8.0     136.0     200.8      0.451771      0.760487         0.338542             0.313528             0.686472       1      1.0   5.0                    0           9.0      0.562500     0.000000                     0             0     0.771151\n",
      "15      2    20              0         4379.4        1629.4          266.6         168.8          94.8            324.6     422.6       3.2     118.4     191.4      0.470440      0.686512         0.329746             0.338788             0.661212       0      0.0   4.0                    1           8.0      0.000000     0.000000                     0             0     0.838273\n",
      "16      3     1              0         5838.6        1809.0          420.4         187.6         107.2            425.2     543.2       5.6     151.2     283.4      0.407579      0.762175         0.353344             0.346510             0.653490       0      1.0   4.0                    1           2.0      0.562500     0.500000                     1             0     0.858300\n",
      "17      3     3              0         4248.8        1373.8          305.0         187.4          55.8            273.0     352.0       0.8      98.4     187.0      0.443021      0.746851         0.318376             0.318278             0.681722       0      0.0   1.0                    2           8.0      0.687500     0.333333                     2             1     0.779217\n",
      "18      3     5              0         3663.2        1212.0          236.8         113.6          53.6            276.8     389.6       3.2      76.0     183.2      0.409415      0.743276         0.319797             0.344043             0.655957       0      0.0   7.0                    0           9.0      0.312500     0.000000                     0             0     0.692518\n",
      "19      3     6              4         5675.8        2089.2          415.4         264.0         101.4            383.8     445.0       1.6     151.2     251.6      0.421207      0.796097         0.331719             0.295209             0.704791       1      1.0   4.0                    2           8.0      0.593750     0.000000                     2             0     0.792457\n",
      "20      3     7              0         4443.2        1520.0          316.8         170.4          59.2            344.8     403.2       4.0     124.8     204.8      0.409291      0.786355         0.333333             0.332378             0.667622       0      1.0   6.0                    0           9.0      0.312500     0.000000                     0             0     0.704688\n",
      "21      3     8              3         5283.2        2102.8          433.4         212.6         123.4            368.0     510.4       7.2     139.2     230.8      0.434310      0.761166         0.330558             0.319838             0.680162       1      1.0   1.0                    2           1.0      0.875000     0.857143                     2             1     0.954726\n",
      "22      3     9              1         4646.4        1357.6          321.4         204.8          74.2            297.0     437.6       2.6     119.2     230.8      0.411476      0.734356         0.325719             0.348694             0.651306       0      0.0   3.0                    1           8.0      0.625000     0.333333                     1             0     0.791992\n",
      "23      3    10              1         3683.2        1366.4          207.2         116.0          66.4            283.2     361.6       4.0      90.4     172.0      0.375087      0.798013         0.316258             0.315217             0.684783       1      0.0   6.0                    0           9.0      0.375000     0.000000                     0             0     0.603371\n",
      "24      3    11              2         5373.6        1838.0          463.6         229.0          65.6            345.4     503.0       4.2     142.0     211.8      0.451229      0.690432         0.377828             0.288371             0.711629       0      1.0   2.0                    2           4.0      0.656250     0.500000                     2             0     0.875441\n",
      "25      3    12              0         6239.8        2138.4          402.0         276.8         113.6            463.4     608.4       4.8     158.2     265.4      0.414081      0.738918         0.330700             0.353098             0.646902       0      0.0   5.0                    1           9.0      0.000000     0.000000                     0             0     0.760030\n",
      "26      3    13              0         3737.0        1092.0          260.2         146.6          52.8            299.6     351.4       0.8      81.6     214.2      0.382865      0.706856         0.312500             0.292547             0.707453       1      0.0   5.0                    1           9.0      0.406250     0.000000                     0             0     0.680037\n",
      "27      3    14              1         5115.0        1528.4          418.6         201.6          80.8            365.2     457.2       2.4     128.6     243.8      0.406775      0.724561         0.368357             0.284381             0.715619       1      0.0   7.0                    0           9.0      0.343750     0.000000                     0             0     0.704449\n",
      "28      3    15              0         5552.0        1911.0          468.2         225.4         132.2            405.2     502.0       4.0     133.0     260.0      0.422222      0.736000         0.388502             0.339939             0.660061       1      0.0   2.0                    2           4.0      0.700000     0.600000                     1             0     0.874868\n",
      "29      3    17              0         4638.4        1376.8          341.6         194.4          86.4            296.8     424.8       4.0     117.6     204.8      0.382900      0.690037         0.300000             0.316583             0.683417       1      1.0   8.0                    0           9.0      0.312500     0.000000                     0             0     0.674616\n",
      "30      3    19              0         4830.2        1667.2          380.0         140.6         125.0            348.8     458.8       6.0     122.0     191.8      0.443833      0.751662         0.315789             0.274467             0.725533       1      1.0   3.0                    1           8.0      0.736842     0.000000                     1             0     0.859805\n",
      "31      3    20              0         4409.6        1244.8          297.6         183.2         100.0            324.0     354.4       1.6     102.4     212.0      0.383219      0.652893         0.298742             0.332311             0.667689       0      1.0   8.0                    1           9.0      0.000000     0.000000                     0             0     0.716412\n",
      "32      4     1              0         5039.4        1720.0          408.4         195.8          71.0            309.2     470.2       4.8     130.0     217.4      0.424152      0.743842         0.402111             0.323006             0.676994       0      1.0   2.0                    2           8.0      0.000000     0.000000                     0             0     0.780772\n",
      "33      4     3              1         5121.6        1772.4          399.8         183.8          54.6            372.2     450.6       7.2     145.4     208.6      0.407056      0.740547         0.337331             0.304146             0.695854       0      1.0   7.0                    2           9.0      0.312500     0.000000                     2             1     0.717335\n",
      "34      4     4              1         5558.4        1839.2          444.8         261.6          83.2            352.0     515.2       4.8     145.6     230.4      0.418440      0.760252         0.320388             0.339216             0.660784       0      1.0   0.0                    0           9.0      0.000000     0.000000                     0             0     0.000000\n",
      "35      4     5              0         5319.2        1789.6          391.2         184.8         132.0            459.2     508.0       2.4     151.2     225.6      0.403395      0.743551         0.287281             0.318966             0.681034       0      1.0   8.0                    0           9.0      0.409091     0.000000                     0             0     0.643652\n",
      "36      4     6              7         6126.0        2306.4          541.6         235.2          97.4            432.6     405.8       0.0     166.0     225.4      0.421387      0.822396         0.334915             0.288076             0.711924       1      1.0   2.0                    3           8.0      0.750000     0.333333                     3             0     0.774453\n",
      "37      4     7              1         5152.4        1716.8          389.4         220.4          98.8            346.4     470.6       7.4     120.4     239.0      0.419661      0.781444         0.369752             0.337049             0.662951       0      0.0   4.0                    1           8.0      0.500000     0.333333                     1             0     0.778385\n",
      "38      4     8              6         6514.2        2542.0          531.2         250.0         153.8            479.6     675.4      14.8     172.6     283.0      0.439400      0.757696         0.377013             0.292119             0.707881       1      1.0   1.0                    3           1.0      0.781250     1.000000                     3             1     0.961362\n",
      "39      4    10              0         4528.0        1524.8          318.4         176.8          66.4            318.4     433.6       4.8     109.6     208.0      0.406944      0.661826         0.332627             0.311054             0.688946       1      1.0   8.0                    0           9.0      0.000000     0.000000                     0             0     0.539985\n",
      "40      4    11              1         5828.8        2032.4          458.4         221.4         109.6            374.6     522.8       5.6     159.8     214.0      0.446961      0.736285         0.373213             0.279768             0.720232       0      0.0   1.0                    3           2.0      0.562500     0.500000                     3             0     0.867429\n",
      "41      4    13              0         5704.8        1537.8          425.0         289.6          70.4            433.4     586.4       0.8     110.4     324.8      0.405714      0.686840         0.304530             0.341880             0.658120       1      0.0   7.0                    1           9.0      0.000000     0.000000                     0             0     0.700615\n",
      "42      4    15              0         4628.0        1684.8          328.0         176.0         100.0            315.2     473.6       4.8     117.6     179.2      0.431743      0.753555         0.309322             0.327887             0.672113       1      1.0   6.0                    2           9.0      0.437500     0.000000                     1             0     0.713122\n",
      "43      4    16              0         5107.8        1927.0          409.2         169.4         150.0            415.4     485.4       2.4     143.2     194.8      0.428678      0.772245         0.323280             0.317549             0.682451       1      0.0   0.0                    0           9.0      0.625000     0.400000                     2             0     0.000000\n",
      "44      4    17              0         5710.8        1980.0          431.2         239.0         130.2            396.4     511.0       3.2     163.6     246.2      0.416239      0.783818         0.340386             0.328305             0.671695       1      0.0   4.0                    1           8.0      0.562500     0.000000                     2             0     0.758935\n",
      "45      4    20              1         4936.6        1576.4          421.8         155.4          51.2            331.6     440.6       2.4     117.4     231.8      0.418202      0.743368         0.366206             0.324208             0.675792       0      0.0   3.0                    2           4.0      0.531250     0.600000                     1             1     0.838728\n",
      "46      5     1              0         5558.0        1658.0          432.2         218.6          98.8            381.8     573.6       4.8     158.8     246.8      0.415961      0.768606         0.338867             0.334084             0.665916       0      0.0   2.0                    3           8.0      0.529412     0.000000                     1             0     0.806379\n",
      "47      5     4              1         3683.2        1421.2          255.0         136.8          70.8            221.0     370.0       4.0      87.2     160.8      0.423694      0.767525         0.346563             0.315856             0.684144       0      1.0   3.0                    1           4.0      0.529412     0.500000                     1             0     0.856643\n",
      "48      5     5              2         6131.6        2091.6          494.8         231.8         143.6            483.8     556.8       2.4     166.4     271.8      0.431497      0.706588         0.367267             0.304706             0.695294       0      1.0   1.0                    1           1.0      0.735294     0.750000                     1             1     0.914296\n",
      "49      5     6              7         5559.6        2022.6          408.2         212.2         115.0            396.0     442.0       1.6     113.8     281.0      0.419031      0.752134         0.342189             0.288810             0.711190       1      0.0   2.0                    4           8.0      0.588235     0.333333                     4             0     0.829395\n",
      "50      5     7              1         5572.8        2078.0          418.8         229.4         109.0            355.4     556.0       4.0     121.4     260.2      0.431134      0.789369         0.385230             0.356148             0.643852       0      0.0   5.0                    1           9.0      0.000000     0.000000                     0             0     0.770868\n",
      "51      5     8              6         5967.8        2152.8          572.2         214.6         149.8            448.8     556.8       8.4     179.4     202.8      0.426954      0.779744         0.337527             0.274394             0.725606       1      1.0   1.0                    4           2.0      0.705882     0.555556                     4             1     0.949490\n",
      "52      5    10              0         4185.2        1361.8          417.6         158.6          69.0            358.8     441.4       6.4     120.8     176.6      0.404230      0.767442         0.344685             0.292591             0.707409       1      1.0   4.0                    1           8.0      0.529412     0.333333                     1             0     0.686523\n",
      "53      5    11              1         4514.4        1671.2          294.4         164.0          91.2            301.6     364.8       2.4     104.8     179.2      0.446858      0.805668         0.361884             0.297590             0.702410       0      1.0   6.0                    3           9.0      0.470588     0.000000                     3             0     0.757567\n",
      "54      5    13              0         4407.0        1491.4          235.8         198.0          74.6            288.4     435.6       7.2     128.6     194.2      0.411591      0.703810         0.345378             0.345539             0.654461       1      0.0   7.0                    1           9.0      0.000000     0.000000                     0             0     0.676073\n",
      "55      5    15              1         5578.2        1885.4          461.6         240.8          99.0            366.8     521.0       5.6     138.8     266.6      0.410017      0.682870         0.315117             0.323327             0.676673       1      1.0   3.0                    3           4.0      0.750000     0.500000                     1             0     0.850964\n",
      "56      5    16              0         5673.2        2121.6          432.0         187.2         128.4            446.2     537.4       4.0     151.0     257.4      0.409729      0.741272         0.232143             0.327921             0.672079       1      0.0   6.0                    0           9.0      0.500000     0.000000                     0             0     0.734199\n",
      "57      5    17              2         5187.8        2125.0          433.0         173.0         114.8            376.6     501.6       6.4     129.4     234.8      0.428571      0.769766         0.324043             0.312075             0.687925       1      1.0   5.0                    1           9.0      0.529412     0.000000                     2             0     0.778708\n",
      "58      5    20              1         5553.6        2031.6          461.0         190.8          78.4            372.0     533.2       2.4     156.6     237.4      0.411808      0.743809         0.320324             0.341598             0.658402       0      1.0   7.0                    2           9.0      0.000000     0.000000                     0             0     0.737162\n",
      "59      6     1              0         5573.8        1798.6          445.4         213.2         105.6            387.8     507.6       2.4     154.4     229.6      0.411912      0.758097         0.302179             0.295468             0.704532       0      0.0   5.0                    3           9.0      0.470588     0.000000                     1             0     0.711238\n",
      "60      6     4              0         5939.4        1956.0          486.2         257.2         129.2            406.2     548.8       1.6     150.2     263.4      0.425909      0.728310         0.314640             0.296918             0.703082       0      1.0   1.0                    2           2.0      0.529412     0.625000                     2             0     0.931192\n",
      "61      6     5              2         6235.4        2041.0          550.8         246.2         124.2            461.4     559.4       5.6     183.6     260.4      0.417672      0.711805         0.294286             0.324212             0.675788       0      1.0   3.0                    2           8.0      0.500000     0.333333                     2             1     0.843474\n",
      "62      6     6              9         5941.4        2048.2          370.2         208.0          84.0            371.0     445.0       1.6     156.6     215.0      0.424437      0.751827         0.348075             0.307356             0.692644       1      1.0   6.0                    4           9.0      0.382353     0.000000                     4             0     0.706399\n",
      "63      6     7              2         5144.6        1775.6          405.4         225.6         104.2            366.6     524.8      11.2     143.2     229.6      0.406262      0.783679         0.344105             0.353731             0.646269       0      1.0   6.0                    1           9.0      0.441176     0.000000                     0             0     0.766072\n",
      "64      6     8              8         5778.8        2244.2          521.0         223.0         125.2            425.0     595.4       4.2     141.4     252.6      0.432350      0.750779         0.377370             0.266394             0.733606       1      1.0   1.0                    5           8.0      0.000000     0.000000                     0             0     0.865967\n",
      "65      6    10              0         3637.8        1269.2          276.2         117.8          94.2            301.6     361.0       1.6      65.6     193.4      0.400036      0.741826         0.359413             0.291667             0.708333       1      0.0   3.0                    2           8.0      0.529412     0.000000                     2             1     0.637691\n",
      "66      6    11              0         5249.6        1740.0          438.2         172.0          96.4            380.2     444.6       1.8     116.8     234.6      0.429838      0.805540         0.355945             0.240077             0.759923       0      1.0   2.0                    4           4.0      0.611111     0.400000                     1             0     0.840348\n",
      "67      6    13              1         6355.2        2266.6          422.8         252.6         135.8            406.6     659.2      15.2     184.8     272.8      0.436756      0.742463         0.365657             0.323246             0.676754       1      0.0   5.0                    1           9.0      0.500000     0.000000                     0             0     0.714187\n",
      "68      6    15              0         4548.6        1465.6          357.6         219.6          84.2            337.6     445.2       2.4      92.4     221.6      0.436481      0.702828         0.358156             0.373890             0.626110       1      1.0   4.0                    4           4.0      0.529412     0.500000                     2             0     0.835865\n",
      "69      6    16              2         3574.2        1209.6          235.0         118.8          27.8            245.6     330.4       2.4     115.6     183.8      0.424512      0.793679         0.355580             0.281917             0.718083       1      0.0   7.0                    0           9.0      0.500000     0.333333                     3             1     0.685736\n",
      "70      6    17              3         3816.2        1507.2          305.2         139.8          95.6            264.8     329.8       1.6      86.4     183.0      0.442233      0.771382         0.391626             0.309993             0.690007       1      1.0   2.0                    2           1.0      0.588235     0.750000                     3             0     0.928234\n",
      "71      6    20              1         5266.0        1624.6          314.6         182.8          98.2            333.2     537.8       2.4     140.0     235.6      0.432134      0.703641         0.394967             0.338342             0.661658       0      0.0   4.0                    3           8.0      0.437500     0.000000                     3             0     0.804248\n",
      "72      7     1              0         4128.8        1288.0          253.6         167.2          73.6            312.0     423.2       6.4     116.0     181.6      0.403472      0.730693         0.348018             0.326146             0.673854       0      0.0   6.0                    3           9.0      0.300000     0.000000                     0             0     0.606457\n",
      "73      7     2              0         4832.4        1270.0          331.8         167.6          78.4            299.0     571.6       3.4      96.6     281.8      0.395122      0.672919         0.334218             0.353846             0.646154       0      0.0   0.0                    0           9.0      0.000000     0.000000                     0             0     0.000000\n",
      "74      7     4              1         4967.8        1982.0          416.6         179.2         103.0            328.8     419.6       0.8     142.2     214.8      0.454006      0.753047         0.342163             0.290361             0.709639       0      1.0   1.0                    3           1.0      0.764706     0.625000                     3             0     0.930767\n",
      "75      7     5              2         5457.6        1906.6          347.0         193.2         129.6            438.2     567.2      10.8     150.8     222.8      0.395163      0.687174         0.313850             0.329663             0.670337       0      1.0   4.0                    3           8.0      0.470588     0.000000                     3             1     0.696844\n",
      "76      7     6             10         5666.6        1822.2          525.4         213.0          81.4            374.2     503.8       4.8     140.2     266.2      0.432599      0.756796         0.312212             0.291158             0.708842       1      1.0   3.0                    5           4.0      0.558824     0.400000                     5             0     0.737546\n",
      "77      7     7              2         5640.0        1796.0          436.8         253.6          61.4            386.2     500.6       2.6     137.2     250.8      0.392134      0.778029         0.339004             0.303077             0.696923       0      1.0   2.0                    2           4.0      0.617647     0.500000                     1             0     0.840694\n",
      "78      7     8              8         4523.8        1550.0          422.6         171.6          99.4            330.8     473.8       6.4     105.0     197.0      0.443665      0.694177         0.311359             0.279420             0.720580       1      1.0   4.0                    6           8.0      0.666667     0.000000                     1             0     0.824120\n",
      "79      7    10              0         3386.4        1201.6          260.8         129.6          92.8            295.2     364.0       2.4      86.4     182.4      0.412804      0.711538         0.365217             0.303354             0.696646       1      0.0   6.0                    2           9.0      0.411765     0.000000                     2             1     0.548481\n",
      "80      7    11              0         3134.4        1002.4          219.2         113.2          50.6            251.0     295.2       1.0      47.8     193.4      0.417907      0.814275         0.330282             0.290900             0.709100       0      0.0   3.0                    5           8.0      0.529412     0.000000                     2             0     0.841345\n",
      "81      7    13              2         4322.6        1518.0          400.0         155.6          71.2            302.2     444.2       5.6     114.6     210.4      0.426955      0.786673         0.328882             0.301093             0.698907       1      0.0   5.0                    1           9.0      0.000000     0.000000                     0             0     0.687066\n",
      "82      7    15              1         4721.0        1725.6          373.2         214.4          75.6            328.2     432.8       1.0     115.2     208.8      0.430990      0.697272         0.374625             0.332472             0.667528       1      1.0   1.0                    5           1.0      0.735294     0.875000                     3             1     0.813304\n",
      "83      7    16              0         4034.6        1171.6          347.8         115.4          34.4            299.2     338.2       4.8     106.0     182.0      0.413723      0.814214         0.338308             0.241148             0.758852       1      0.0   7.0                    0           9.0      0.205882     0.000000                     3             1     0.622350\n",
      "84      7    17              4         5715.2        2071.6          393.0         153.2         121.8            397.2     540.6       8.0     166.2     240.0      0.450335      0.794937         0.348735             0.290163             0.709837       1      1.0   2.0                    3           8.0      0.588235     0.333333                     4             0     0.871588\n",
      "85      7    20              2         4622.2        1581.8          294.0         172.8          53.0            270.4     458.6       4.8     119.0     196.0      0.414434      0.716658         0.337488             0.306020             0.693980       0      1.0   5.0                    3           9.0      0.470588     0.000000                     3             0     0.751628\n",
      "86      8     2              0         3501.6        1236.8          308.4         138.4          49.6            234.6     326.6       1.6     109.2     156.4      0.386380      0.760849         0.276515             0.335463             0.664537       0      0.0   7.0                    0           9.0      0.000000     0.000000                     0             0     0.652075\n",
      "87      8     4              1         4776.6        1779.0          430.8         177.2         120.6            320.2     404.2       0.0     127.0     234.6      0.437951      0.802429         0.348527             0.268883             0.731117       0      1.0   1.0                    4           4.0      0.764706     0.600000                     4             1     0.902848\n",
      "88      8     5              3         5654.4        2165.0          522.0         209.4          81.8            444.0     612.8       2.4     144.0     262.4      0.422520      0.738951         0.340098             0.329803             0.670197       0      1.0   2.0                    4           1.0      0.676471     0.700000                     4             1     0.936491\n",
      "89      8     6             12         5720.4        2166.8          394.4         233.0          82.6            432.2     569.4       6.4     130.8     280.0      0.445802      0.741791         0.339907             0.287155             0.712845       1      0.0   3.0                    6           8.0      0.785714     0.333333                     1             0     0.762779\n",
      "90      8     7              4         6277.6        2340.6          457.8         324.0         117.0            457.4     556.6       4.4     186.8     248.0      0.414496      0.743124         0.303678             0.318420             0.681580       0      1.0   3.0                    3           8.0      0.617647     0.000000                     2             0     0.850908\n",
      "91      8     8              3         5012.8        1774.8          390.4         200.6          74.8            334.2     506.2       5.0     109.8     234.8      0.440021      0.778404         0.276155             0.320900             0.679100       1      0.0   1.0                    7           4.0      0.700000     0.000000                     4             1     0.853866\n",
      "92      8    10              1         3954.2        1591.2          331.4         105.6          44.2            300.0     330.6       0.0     109.6     176.4      0.431095      0.770161         0.366667             0.265177             0.734823       1      0.0   7.0                    2           9.0      0.000000     0.000000                     0             0     0.661392\n",
      "93      8    11              0         4523.2        1508.8          296.8         174.4          78.4            328.8     436.0       2.4     105.6     208.0      0.402786      0.776660         0.345528             0.285714             0.714286       0      1.0   5.0                    5           9.0      0.323529     0.000000                     2             0     0.712008\n",
      "94      8    13              3         6538.0        2946.8          570.4         262.6         120.8            463.8     677.0       7.2     135.2     304.4      0.432145      0.781324         0.367793             0.291339             0.708661       1      1.0   5.0                    1           9.0      0.529412     0.000000                     0             0     0.773233\n",
      "95      8    15              3         5811.4        2001.8          443.8         268.4          68.8            396.0     536.4       1.6     122.6     310.0      0.404055      0.705108         0.346232             0.323268             0.676732       1      1.0   2.0                    6           2.0      0.000000     0.000000                     0             0     0.703437\n",
      "96      8    16              1         5041.8        1779.2          415.4         187.4          80.2            347.0     451.0       1.6     172.4     200.4      0.401667      0.793867         0.332410             0.285152             0.714848       1      1.0   6.0                    0           9.0      0.382353     0.000000                     3             1     0.624798\n",
      "97      8    17              6         5165.8        2036.8          425.4         169.0         106.6            418.4     512.6       4.2     135.8     273.6      0.436763      0.775157         0.338162             0.301364             0.698636       1      1.0   4.0                    4           8.0      0.529412     0.333333                     5             0     0.831861\n",
      "98      8    20              2         5740.0        2322.0          477.4         251.0         103.8            430.6     635.0      10.6     142.8     269.8      0.455556      0.737705         0.350759             0.295990             0.704010       0      0.0   4.0                    4           8.0      0.529412     0.000000                     4             0     0.849784\n",
      "99      9     0              2         3998.8        1387.8          296.0         139.2          52.8            291.6     376.4       1.0      78.4     224.6      0.412159      0.759247         0.380527             0.320954             0.679046       0      0.0   0.0                    0           9.0      0.000000     0.000000                     0             0     0.000000\n",
      "100     9     2              1         4684.4        1700.6          409.4         192.2          86.4            318.8     392.2       3.2     107.2     220.4      0.423035      0.679867         0.377715             0.320976             0.679024       0      0.0   6.0                    0           9.0      0.000000     0.000000                     0             0     0.727112\n",
      "101     9     4              0         4113.2        1656.6          419.4         164.8          38.4            322.6     361.8       2.4     107.8     180.8      0.433347      0.779345         0.340308             0.276609             0.723391       0      1.0   3.0                    5           8.0      0.529412     0.333333                     5             1     0.877561\n",
      "102     9     5              5         5294.6        2043.2          414.4         190.2          96.2            389.2     541.8       6.2     108.6     235.2      0.429391      0.756632         0.344406             0.289120             0.710880       0      1.0   1.0                    5           2.0      0.705882     0.545455                     5             1     0.888784\n",
      "103     9     6              3         5167.6        2062.6          402.4         208.2          79.6            454.6     522.6       2.4     129.8     243.8      0.420247      0.779707         0.354482             0.309166             0.690834       1      0.0   5.0                    6           9.0      0.382353     0.000000                     1             0     0.748719\n",
      "104     9     7              6         6002.6        2336.8          528.0         315.2         118.8            552.2     625.0       5.8     149.2     283.6      0.422171      0.758412         0.314124             0.295885             0.704115       0      1.0   2.0                    4           4.0      0.531250     0.000000                     1             0     0.861372\n",
      "105     9     8             10         5566.6        2226.6          362.6         194.2         167.2            447.8     633.8       8.0     152.2     274.2      0.421469      0.751406         0.351108             0.283454             0.716546       1      1.0   7.0                    7           9.0      0.294118     0.000000                     4             1     0.722202\n",
      "106     9    10              1         5034.2        1969.0          444.8         166.6          99.6            391.4     479.8       5.6     137.2     241.6      0.414130      0.804724         0.353047             0.304284             0.695716       1      0.0   6.0                    2           9.0      0.294118     0.000000                     0             0     0.703300\n",
      "107     9    11              1         5442.2        1930.8          407.0         232.6          88.8            464.0     490.2       1.6     136.6     238.6      0.417247      0.740009         0.364175             0.262676             0.737324       0      1.0   4.0                    6           8.0      0.470588     0.333333                     3             0     0.833995\n",
      "108     9    13              4         4578.0        1921.6          465.2         173.8          96.4            312.0     412.8       2.6     118.4     212.2      0.429216      0.810275         0.351689             0.235754             0.764246       1      0.0   1.0                    2           1.0      0.000000     0.000000                     0             0     1.000000\n",
      "109     9    15              1         4155.8        1555.4          317.4         193.6          59.6            309.4     358.0       3.2     111.2     193.6      0.400698      0.795343         0.346451             0.379890             0.620110       1      1.0   3.0                    7           8.0      0.558824     0.333333                     1             0     0.791061\n",
      "110     9    16              1         4620.2        1739.6          427.8         176.2          98.8            359.8     439.0       1.8     137.0     194.2      0.450714      0.803607         0.374734             0.270426             0.729574       1      1.0   2.0                    1           4.0      0.588235     0.400000                     4             2     0.746074\n",
      "111     9    17             15         4589.6        1745.0          364.8         164.2         114.4            338.8     404.4       1.6     112.8     218.4      0.446923      0.773686         0.349599             0.301070             0.698930       1      1.0   4.0                    5           8.0      0.315789     0.000000                     0             0     0.850751\n",
      "112     9    20              2         4570.2        1752.0          292.8         170.6          85.0            343.0     496.4       7.2      96.8     255.4      0.432567      0.757730         0.307042             0.343790             0.656210       0      0.0   5.0                    4           9.0      0.533333     0.000000                     0             0     0.776127\n",
      "113    10     0              4         4967.2        1748.8          391.2         200.0          92.8            379.2     556.8       8.0     146.4     219.2      0.408696      0.744932         0.320961             0.329767             0.670233       0      1.0   7.0                    0           9.0      0.117647     0.000000                     0             0     0.581072\n",
      "114    10     2              1         4887.2        1737.6          401.2         184.2         106.4            332.2     419.8       2.4     124.8     226.4      0.432983      0.704605         0.319202             0.293416             0.706584       0      0.0   5.0                    0           9.0      0.352941     0.000000                     0             0     0.734207\n",
      "115    10     4              0         5464.2        2261.6          511.2         184.6          86.4            397.6     523.8       2.4     156.8     249.4      0.420943      0.768038         0.337412             0.290785             0.709215       0      0.0   2.0                    6           8.0      0.617647     0.333333                     6             2     0.783522\n",
      "116    10     5              7         7024.6        2671.0          581.4         299.8         121.8            487.2     697.2       3.2     158.4     311.2      0.431856      0.743217         0.353114             0.306477             0.693523       0      1.0   1.0                    6           1.0      0.647059     0.777778                     6             1     0.844141\n",
      "117    10     7              9         5879.0        2036.8          411.8         279.2         131.2            448.0     659.6       6.4     168.4     264.6      0.411874      0.748066         0.350432             0.328059             0.671941       0      1.0   4.0                    5           8.0      0.500000     0.333333                     2             0     0.844948\n",
      "118    10     8             16         6706.2        2850.6          601.6         267.0         194.8            628.0     615.8       5.2     212.8     258.8      0.432423      0.767782         0.346312             0.275141             0.724859       1      1.0   3.0                    8           4.0      0.588235     0.500000                     5             1     0.914711\n",
      "119    10    10              3         4097.6        1775.2          332.0         184.0         106.4            268.0     428.0       5.6      90.4     180.8      0.440716      0.791483         0.331210             0.324719             0.675281       1      0.0   7.0                    2           9.0      0.000000     0.000000                     0             0     0.743947\n",
      "120    10    11              1         5278.4        1976.6          425.0         217.6          87.0            389.6     503.0       3.2     135.6     260.2      0.421936      0.740016         0.365750             0.315115             0.684885       0      0.0   3.0                    7           4.0      0.558824     0.500000                     4             0     0.828984\n",
      "121    10    13              4         5452.4        2704.4          494.2         216.4         114.2            391.6     621.4       8.8     163.4     242.2      0.439955      0.840965         0.328883             0.299480             0.700520       1      1.0   6.0                    2           9.0      0.470588     0.000000                     0             0     0.774778\n",
      "122    10    15              1         4910.8        1974.6          335.8         245.0          57.8            377.0     489.6       2.6     128.0     236.6      0.425118      0.776826         0.417377             0.340538             0.659462       1      0.0   4.0                    8           8.0      0.529412     0.333333                     2             0     0.754228\n",
      "123    10    16              2         4962.6        1965.2          475.4         199.4          97.2            358.6     416.4       2.4     126.6     213.6      0.437283      0.816318         0.331937             0.214196             0.785804       1      1.0   1.0                    2           2.0      0.705882     0.444444                     5             2     0.800304\n",
      "124    10    17              5         6184.8        2219.2          556.2         224.6         142.0            473.4     628.6       3.2     143.6     283.2      0.421574      0.770232         0.320328             0.294490             0.705510       1      1.0   2.0                    6           8.0      0.647059     0.333333                     1             0     0.800583\n",
      "125    10    20              0         5466.0        1982.8          451.4         205.8          72.0            468.8     686.4      11.2     148.8     260.6      0.410634      0.675121         0.326900             0.334992             0.665008       0      1.0   6.0                    4           9.0      0.000000     0.000000                     0             0     0.599861\n",
      "126    11     0              3         6267.4        2382.0          507.2         277.0         130.2            450.4     604.4       4.8     149.2     313.8      0.452721      0.726693         0.322600             0.311232             0.688768       0      NaN   2.0                    1           8.0      0.529412     0.000000                     1             1     0.816488\n",
      "127    11     2              1         3225.8        1166.6          208.6         102.4          68.4            250.8     335.4       1.6      70.4     188.8      0.436040      0.724484         0.392555             0.284838             0.715162       0      NaN   5.0                    0           9.0      0.000000     0.000000                     0             0     0.717937\n",
      "128    11     4              1         3374.4        1311.6          269.4         114.6          43.6            249.4     332.8       2.6      72.8     143.6      0.433121      0.793539         0.350923             0.313420             0.686580       0      NaN   6.0                    6           9.0      0.470588     0.000000                     6             2     0.734972\n",
      "129    11     7              6         5906.0        2501.6          446.2         291.8         145.2            431.6     583.6       8.2     137.8     268.8      0.407024      0.834532         0.337719             0.275431             0.724569       0      NaN   1.0                    6           2.0      0.647059     0.600000                     3             0     0.951452\n",
      "130    11     8              6         5208.8        1775.4          492.2         185.2         108.0            397.4     398.6       4.2     136.0     194.0      0.417125      0.821393         0.345703             0.261746             0.738254       1      NaN   3.0                    9           4.0      0.735294     0.400000                     2             0     0.896314\n",
      "131    11    10              3         4489.4        1867.8          409.8         206.0          62.6            326.6     434.6       3.4     145.2     162.8      0.444965      0.805377         0.329381             0.284425             0.715575       1      NaN   5.0                    2           9.0      0.000000     0.000000                     0             0     0.754071\n",
      "132    11    11              2         4154.4        1900.0          360.4         139.4          51.8            306.4     415.2       0.8      88.6     216.0      0.436796      0.818671         0.347022             0.313887             0.686113       0      NaN   7.0                    7           9.0      0.428571     0.000000                     4             1     0.751490\n",
      "133    11    13              6         4853.0        2207.8          428.0         172.0         116.8            395.6     484.2       3.0     100.4     230.4      0.447326      0.801466         0.382956             0.264345             0.735655       1      NaN   1.0                    3           1.0      0.676471     0.636364                     1             0     0.978688\n",
      "134    11    16              2         4497.8        1918.8          405.8         215.2          83.0            282.4     344.2       4.0     142.4     160.6      0.432803      0.820147         0.364933             0.251796             0.748204       1      NaN   4.0                    3           8.0      0.441176     0.333333                     6             2     0.755962\n",
      "135    11    17              8         6151.2        2408.2          487.8         223.6          93.4            423.4     597.0       8.8     182.2     228.6      0.436524      0.812097         0.362116             0.310096             0.689904       1      NaN   2.0                    7           8.0      0.588235     0.333333                     2             0     0.869611\n",
      "136    11    18             10         2455.8         896.2          185.6         101.6          29.6            175.6     245.0       0.0      44.0     147.0      0.391533      0.781983         0.282704             0.264014             0.735986       1      NaN   0.0                    0           9.0      0.000000     0.000000                     0             0     0.000000\n",
      "137    11    20              2         4056.6        1500.6          270.4         202.6          76.4            296.4     393.4       1.6     110.4     183.2      0.418357      0.710526         0.338135             0.336400             0.663600       0      NaN   4.0                    5           8.0      0.125000     0.000000                     1             0     0.853112\n",
      "\u001b[1mModel: Random Forest\u001b[0m\n",
      "Selected Features: ['total_blocks', 'total_orebounds_pct', 'rank', 'total_minutes', 'total_three_pct', 'coach_po_wr', 'total_drebounds_pct', 'total_fg_pct', 'coach_reg_wr', 'team_playoffs_count', 'total_pf', 'playoff_rank', 'total_assists', 'coach_playoffs_count', 'total_points', 'total_gs', 'total_gp', 'total_ft_pct', 'tmid', 'total_turnovers', 'total_dq', 'total_steals', 'team_rating', 'year']\n",
      "Accuracy:0.8461538461538461\n",
      "\n",
      "Selected Features: ['total_assists', 'total_orebounds_pct', 'tmid', 'total_steals', 'total_fg_pct', 'team_rating', 'total_points', 'total_gs', 'total_three_pct', 'year']\n",
      "Accuracy:0.7692307692307693\n",
      "\n",
      "Selected Features: ['total_assists', 'total_ft_pct', 'total_orebounds_pct', 'tmid', 'total_steals', 'total_fg_pct', 'team_rating', 'total_points', 'total_gs', 'total_three_pct', 'year']\n",
      "Accuracy:0.7692307692307693\n",
      "\n",
      "\u001b[1mModel: Logistic Regression\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "min_features = 5\n",
    "print(merged_data.columns)\n",
    "\n",
    "rfe_classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42,max_iter=10000),\n",
    "    'Support Vector Machine': SVC(random_state=42, kernel='linear'),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "classifiers_features = {}\n",
    "\n",
    "total_features = len(x_train.columns)\n",
    "print(merged_data.to_string())\n",
    "for model_name, model in rfe_classifiers.items():\n",
    "    print(f\"\\033[1mModel: {model_name}\\033[0m\")\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for i in range(min_features, total_features):\n",
    "        rfe = RFE(model, n_features_to_select=i)\n",
    "        rfe.fit(x_train, y_train)\n",
    "        \n",
    "        selected_features = set(x_train.columns[rfe.support_])\n",
    "        selected_features.add(\"tmid\")\n",
    "        selected_features.add(\"year\")\n",
    "        selected_features = list(selected_features)\n",
    "\n",
    "        model.fit(x_train[selected_features], y_train)\n",
    "\n",
    "        accuracy = model.score(x_test[selected_features], y_test)\n",
    "\n",
    "        results.append((selected_features, accuracy))\n",
    "\n",
    "    # Sort the results based on accuracy in descending order\n",
    "    results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    classifiers_features[model_name] = results[0][0]\n",
    "    # Print the results\n",
    "    for features, accuracy in results[:3]:\n",
    "        print(\"Selected Features:\", features)\n",
    "        print(\"Accuracy:\" + str(accuracy) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since RFE doesn't work with KNN, we will be using SelectKBest which produces the same process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['team_players_rating', 'rank', 'year', 'total_assists', 'playoff_rank', 'tmid']\n",
      "Accuracy:0.6923076923076923\n",
      "\n",
      "Selected Features: ['coach_reg_wr', 'team_players_rating', 'coach_playoffs_count', 'total_assists', 'year', 'team_playoffs_count', 'tmid']\n",
      "Accuracy:0.6923076923076923\n",
      "\n",
      "Selected Features: ['total_dq', 'coach_reg_wr', 'team_rating', 'total_steals', 'team_players_rating', 'total_points', 'total_gs', 'rank', 'player_awards', 'total_blocks', 'coach_playoffs_count', 'total_assists', 'year', 'total_three_pct', 'total_minutes', 'tmid']\n",
      "Accuracy:0.6923076923076923\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "results = []\n",
    "\n",
    "for i in range(min_features, total_features):\n",
    "    knn = KNeighborsClassifier()\n",
    "\n",
    "    selector = SelectKBest(score_func=mutual_info_classif, k=i)\n",
    "    selector.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "    selected_features = set(x_train.columns[selector.get_support()])\n",
    "    selected_features.add(\"tmid\")\n",
    "    selected_features.add(\"year\")\n",
    "    selected_features = list(selected_features)\n",
    "\n",
    "    knn.fit(x_train[selected_features], y_train)\n",
    "\n",
    "    accuracy = knn.score(x_test[selected_features], y_test)\n",
    "\n",
    "    results.append((selected_features, accuracy))\n",
    "\n",
    "results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "classifiers_features[\"K-Nearest Neighbors\"] = results[0][0]\n",
    "\n",
    "# Print the best 3 results\n",
    "for features, accuracy in results[:3]:\n",
    "    print(\"Selected Features:\", features)\n",
    "    print(\"Accuracy:\" + str(accuracy) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch\n",
    "Now that we know the best features for each model, we will use gridsearch to fine tune its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest: 1.0\n",
      "AUC for Random Forest: 1.0\n",
      "0.08999776840209961\n",
      "Accuracy for Logistic Regression: 0.7692307692307693\n",
      "AUC for Logistic Regression: 0.7375\n",
      "0.007999658584594727\n",
      "Accuracy for Support Vector Machine: 0.6153846153846154\n",
      "AUC for Support Vector Machine: 0.575\n",
      "0.003998756408691406\n",
      "Accuracy for Gradient Boosting: 0.9230769230769231\n",
      "AUC for Gradient Boosting: 0.9\n",
      "0.05000042915344238\n",
      "Accuracy for K-Nearest Neighbors: 0.6923076923076923\n",
      "AUC for K-Nearest Neighbors: 0.675\n",
      "0.003000974655151367\n"
     ]
    }
   ],
   "source": [
    "#best_params = fs.grid_search(classifiers_features,x_train,x_test,y_train,y_test)\n",
    "#print(best_params)\n",
    "\n",
    "# Random Forest -> {'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}\n",
    "\n",
    "# Logistic -> {'C': 100, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear'}\n",
    "\n",
    "# SVM -> {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
    "\n",
    "# Gradient -> {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50}\n",
    "\n",
    "# KNN ->  {'n_neighbors': 10, 'p': 2, 'weights': 'uniform'}\n",
    "\n",
    "import time\n",
    "\n",
    "model_params = {'Random Forest': {'random_state':42, 'bootstrap': False, 'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, 'Logistic Regression': {'random_state':42, 'C': 100, 'fit_intercept': False, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter': 10000}, 'Support Vector Machine': {'random_state':42, 'C': 10, 'gamma': 'scale', 'kernel': 'linear'}, 'Gradient Boosting': {'random_state':42,'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 50}, 'K-Nearest Neighbors': {'n_neighbors': 10, 'p': 2, 'weights': 'uniform'}}\n",
    "\n",
    "final_classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(random_state =42),\n",
    "    'Logistic Regression': LogisticRegression(random_state =42),\n",
    "    'Support Vector Machine': SVC(random_state =42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state =42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "}\n",
    "\n",
    "for model_name, model in final_classifiers.items():\n",
    "    start = time.time()\n",
    "    model.fit(x_train[classifiers_features[model_name]], y_train)\n",
    "    y_pred = model.predict(x_test[classifiers_features[model_name]])\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    end = time.time()\n",
    "    print(f'Accuracy for {model_name}: {accuracy}')\n",
    "    print(f'AUC for {model_name}: {auc}')\n",
    "    print(end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
